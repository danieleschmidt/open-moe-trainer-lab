#!/usr/bin/env python3
"""
Generation 2 Robust MoE Demo - MAKE IT ROBUST

This demo showcases the robust error handling, monitoring, and reliability
features added in Generation 2 of the Open MoE Trainer Lab.

Features demonstrated:
1. Comprehensive health monitoring
2. Advanced error handling and recovery
3. Circuit breaker patterns
4. Retry mechanisms with exponential backoff
5. Ablation study framework
6. Production-ready monitoring

Generation 2: MAKE IT ROBUST - Comprehensive error handling and monitoring
"""

import time
import json
import logging
from pathlib import Path

# Monitoring and error handling
from moe_lab.monitoring.health_monitor import HealthMonitor, ModelHealthChecker, SystemMetrics
from moe_lab.monitoring.error_handler import MoEErrorHandler, CircuitBreaker, RetryHandler, robust_execution
from moe_lab.research.ablation_studies import AblationStudy, AblationConfig


def setup_demo_logging():
    """Setup logging for the demo."""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler('generation2_demo.log')
        ]
    )
    return logging.getLogger("generation2_demo")


def demo_health_monitoring():
    """Demonstrate comprehensive health monitoring."""
    print("=" * 60)
    print("üè• DEMO: Health Monitoring System")
    print("=" * 60)
    
    # Create health monitor
    monitor = HealthMonitor(
        check_interval=10,  # Short interval for demo
        log_file="health_monitor.log"
    )
    
    # Add custom health check
    def custom_moe_check():
        """Custom health check for MoE systems."""
        from moe_lab.monitoring.health_monitor import HealthCheck, HealthStatus
        
        # Simulate checking MoE-specific metrics
        expert_utilization = 0.85  # Simulated
        routing_entropy = 2.1     # Simulated
        
        if expert_utilization < 0.5:
            status = HealthStatus.WARNING
            message = f"Low expert utilization: {expert_utilization:.2f}"
        elif routing_entropy < 1.0:
            status = HealthStatus.WARNING
            message = f"Low routing entropy: {routing_entropy:.2f}"
        else:
            status = HealthStatus.HEALTHY
            message = "MoE routing healthy"
        
        return HealthCheck(
            name="moe_routing",
            status=status,
            message=message,
            details={
                "expert_utilization": expert_utilization,
                "routing_entropy": routing_entropy
            },
            timestamp=time.time(),
            execution_time=0.01
        )
    
    monitor.register_check("moe_routing", custom_moe_check)
    
    print("Running health checks...")
    
    # Run health checks
    check_results = monitor.run_all_checks()
    overall_status = monitor.get_overall_health_status(check_results)
    
    print(f"‚úÖ Overall health status: {overall_status.value}")
    
    for name, check in check_results.items():
        status_emoji = "‚úÖ" if check.status.value == "healthy" else "‚ö†Ô∏è" if check.status.value == "warning" else "‚ùå"
        print(f"  {status_emoji} {name}: {check.message}")
    
    # Get comprehensive health report
    health_report = monitor.get_health_report()
    
    # Save report
    output_file = Path("health_report.json")
    with open(output_file, 'w') as f:
        json.dump(health_report, f, indent=2, default=str)
    
    print(f"üìÑ Health report saved to: {output_file}")
    
    return {
        "overall_status": overall_status.value,
        "checks_passed": sum(1 for check in check_results.values() if check.status.value == "healthy"),
        "total_checks": len(check_results),
        "system_metrics": health_report.get("system_metrics")
    }


def demo_error_handling():
    """Demonstrate advanced error handling and recovery."""
    print("\n" + "=" * 60)
    print("üõ°Ô∏è DEMO: Error Handling and Recovery")
    print("=" * 60)
    
    # Create error handler
    error_handler = MoEErrorHandler(
        log_file="error_handler.log",
        auto_recovery=True
    )
    
    # Simulate various error scenarios
    test_errors = [
        (MemoryError("Simulated memory error"), "memory_intensive_operation"),
        (RuntimeError("Dimension mismatch"), "model_forward_pass"),
        (ValueError("Invalid parameter"), "configuration_validation"),
        (ConnectionError("Network timeout"), "remote_data_fetch")
    ]
    
    recovery_results = []
    
    print("Simulating and handling various errors...")
    
    for error, context in test_errors:
        print(f"\nüîß Handling {type(error).__name__}: {error}")
        
        # Handle error
        recovery_result = error_handler.handle_error(
            error,
            context={"operation": context, "timestamp": time.time()},
            severity=error_handler.ErrorSeverity.MEDIUM
        )
        
        if recovery_result:
            recovery_action = recovery_result.get("recovery_action", "unknown")
            print(f"  ‚úÖ Recovery action: {recovery_action}")
            
            if "suggestion" in recovery_result:
                print(f"  üí° Suggestion: {recovery_result['suggestion']}")
        else:
            print("  ‚ùå No recovery available")
        
        recovery_results.append({
            "error_type": type(error).__name__,
            "context": context,
            "recovery_available": recovery_result is not None,
            "recovery_result": recovery_result
        })
    
    # Get error statistics
    error_stats = error_handler.get_error_statistics()
    print(f"\nüìä Error Statistics:")
    print(f"  Total errors handled: {error_stats['total_errors']}")
    print(f"  Error types: {list(error_stats['error_type_counts'].keys())}")
    
    return {
        "errors_handled": len(recovery_results),
        "recoveries_available": sum(1 for r in recovery_results if r["recovery_available"]),
        "error_statistics": error_stats
    }


def demo_circuit_breaker():
    """Demonstrate circuit breaker pattern."""
    print("\n" + "=" * 60)
    print("‚ö° DEMO: Circuit Breaker Pattern")
    print("=" * 60)
    
    # Create circuit breaker
    circuit_breaker = CircuitBreaker(
        name="model_inference",
        failure_threshold=3,
        timeout=10.0,
        recovery_timeout=5.0
    )
    
    # Simulate function that fails initially then succeeds
    failure_count = 0
    max_failures = 4
    
    def unstable_function():
        nonlocal failure_count
        failure_count += 1
        
        if failure_count <= max_failures:
            raise RuntimeError(f"Simulated failure #{failure_count}")
        
        return f"Success after {failure_count} attempts"
    
    results = []
    
    print("Testing circuit breaker with unstable function...")
    
    # Test multiple calls
    for i in range(8):
        try:
            result = circuit_breaker.call(unstable_function)
            print(f"  Call {i+1}: ‚úÖ {result}")
            results.append({"call": i+1, "success": True, "result": result})
            
        except Exception as e:
            print(f"  Call {i+1}: ‚ùå {e}")
            results.append({"call": i+1, "success": False, "error": str(e)})
        
        # Check circuit breaker state
        state = circuit_breaker.get_state()
        print(f"    Circuit state: {state['state']}, failures: {state['failure_count']}")
        
        time.sleep(0.5)  # Brief delay
    
    # Final state
    final_state = circuit_breaker.get_state()
    print(f"\nüìä Final circuit breaker state:")
    print(f"  State: {final_state['state']}")
    print(f"  Success rate: {final_state['success_rate']:.2%}")
    print(f"  Total requests: {final_state['total_requests']}")
    
    return {
        "total_calls": len(results),
        "successful_calls": sum(1 for r in results if r["success"]),
        "final_state": final_state
    }


def demo_retry_mechanism():
    """Demonstrate retry mechanism with exponential backoff."""
    print("\n" + "=" * 60)
    print("üîÑ DEMO: Retry Mechanism")
    print("=" * 60)
    
    # Create retry handler
    retry_handler = RetryHandler(
        max_retries=3,
        base_delay=0.5,
        max_delay=5.0,
        exponential_base=2.0,
        jitter=True
    )
    
    # Simulate function that succeeds after retries
    attempt_count = 0
    success_after = 2
    
    def unreliable_function():
        nonlocal attempt_count
        attempt_count += 1
        
        if attempt_count <= success_after:
            raise ConnectionError(f"Network timeout (attempt {attempt_count})")
        
        return f"Success on attempt {attempt_count}"
    
    print(f"Testing retry mechanism (succeeds after {success_after} failures)...")
    
    start_time = time.time()
    
    try:
        result = retry_handler.retry(
            unreliable_function,
            retryable_exceptions=(ConnectionError, RuntimeError)
        )
        
        duration = time.time() - start_time
        print(f"‚úÖ Function succeeded: {result}")
        print(f"‚è±Ô∏è Total duration: {duration:.2f} seconds")
        
        return {
            "success": True,
            "attempts": attempt_count,
            "duration": duration,
            "result": result
        }
        
    except Exception as e:
        duration = time.time() - start_time
        print(f"‚ùå Function failed after retries: {e}")
        print(f"‚è±Ô∏è Total duration: {duration:.2f} seconds")
        
        return {
            "success": False,
            "attempts": attempt_count,
            "duration": duration,
            "error": str(e)
        }


@robust_execution(retries=2)
def demo_robust_execution_decorator():
    """Demonstrate robust execution decorator."""
    print("\n" + "=" * 60)
    print("üîí DEMO: Robust Execution Decorator")
    print("=" * 60)
    
    # Simulate function with occasional failures
    import random
    
    if random.random() < 0.7:  # 70% chance of failure
        raise RuntimeError("Simulated random failure")
    
    return "Function executed successfully with robust decorator"


def demo_ablation_study_framework():
    """Demonstrate ablation study framework."""
    print("\n" + "=" * 60)
    print("üß™ DEMO: Ablation Study Framework")
    print("=" * 60)
    
    # Create ablation configuration
    config = AblationConfig(
        study_name="demo_ablation_study",
        study_description="Demonstration of ablation study framework",
        base_config={
            "hidden_size": 128,
            "num_layers": 6,
            "learning_rate": 1e-4
        },
        ablation_params={
            "hidden_size": [64, 128, 256],
            "num_layers": [4, 6, 8],
            "learning_rate": [1e-5, 1e-4, 1e-3]
        },
        num_runs_per_config=1,  # Small for demo
        evaluation_metrics=["perplexity", "throughput", "memory_usage"]
    )
    
    # Mock model and trainer factories
    def mock_model_factory(config):
        """Mock model factory for demo."""
        class MockModel:
            def __init__(self, config):
                self.config = config
                self.hidden_size = config["hidden_size"]
                self.num_layers = config["num_layers"]
        
        return MockModel(config)
    
    def mock_trainer_factory(model, config):
        """Mock trainer factory for demo."""
        class MockTrainer:
            def __init__(self, model, config):
                self.model = model
                self.config = config
            
            def train(self):
                # Simulate training
                time.sleep(0.1)
        
        return MockTrainer(model, config)
    
    def mock_evaluator(model, config):
        """Mock evaluator for demo."""
        import random
        
        # Simulate metrics based on config
        hidden_size = config["hidden_size"]
        num_layers = config["num_layers"]
        learning_rate = config["learning_rate"]
        
        # Simulate realistic relationships
        base_perplexity = 15.0
        perplexity = base_perplexity - (hidden_size / 1000) + random.uniform(-1, 1)
        
        base_throughput = 100.0
        throughput = base_throughput + (hidden_size / 10) + random.uniform(-10, 10)
        
        base_memory = 1.0
        memory_usage = base_memory + (hidden_size * num_layers / 10000) + random.uniform(-0.1, 0.1)
        
        return {
            "perplexity": max(perplexity, 1.0),
            "throughput": max(throughput, 10.0),
            "memory_usage": max(memory_usage, 0.1)
        }
    
    print("Creating ablation study...")
    study = AblationStudy(
        config=config,
        model_factory=mock_model_factory,
        trainer_factory=mock_trainer_factory,
        evaluator=mock_evaluator
    )
    
    print("Generating configurations...")
    configurations = study.generate_configurations()
    print(f"Generated {len(configurations)} configurations")
    
    # Run a subset for demo (full study would be too long)
    print(f"Running ablation study with {min(3, len(configurations))} configurations...")
    
    # Temporarily limit configurations for demo
    original_configs = configurations
    study._configurations = configurations[:3]  # Limit for demo
    
    try:
        # Simulate study execution
        demo_results = []
        for i, config in enumerate(configurations[:3]):
            print(f"  Running configuration {i+1}: hidden_size={config['hidden_size']}, num_layers={config['num_layers']}")
            
            # Simulate result
            metrics = mock_evaluator(None, config)
            demo_results.append({
                "config_idx": i,
                "config": config,
                "metrics": metrics
            })
        
        print("‚úÖ Ablation study demo completed")
        
        # Show sample results
        print("\nüìä Sample Results:")
        for result in demo_results:
            config = result["config"]
            metrics = result["metrics"]
            print(f"  Config {result['config_idx']}: h={config['hidden_size']}, l={config['num_layers']} -> "
                  f"perplexity={metrics['perplexity']:.2f}, throughput={metrics['throughput']:.1f}")
        
        return {
            "total_configurations": len(original_configs),
            "demo_configurations_run": len(demo_results),
            "sample_results": demo_results
        }
        
    except Exception as e:
        print(f"‚ùå Ablation study demo failed: {e}")
        return {"error": str(e)}


def main():
    """Run all Generation 2 robust demos."""
    logger = setup_demo_logging()
    
    print("üî¨ Open MoE Trainer Lab - Generation 2 Robust Demo")
    print("Generation 2: MAKE IT ROBUST - Comprehensive error handling and monitoring")
    print("=" * 80)
    
    # Track all results
    all_results = {}
    
    try:
        # Run all demos
        all_results["health_monitoring"] = demo_health_monitoring()
        all_results["error_handling"] = demo_error_handling()
        all_results["circuit_breaker"] = demo_circuit_breaker()
        all_results["retry_mechanism"] = demo_retry_mechanism()
        
        # Test robust execution decorator
        try:
            result = demo_robust_execution_decorator()
            print(f"‚úÖ Robust execution: {result}")
            all_results["robust_execution"] = {"success": True, "result": result}
        except Exception as e:
            print(f"‚ùå Robust execution failed: {e}")
            all_results["robust_execution"] = {"success": False, "error": str(e)}
        
        all_results["ablation_study"] = demo_ablation_study_framework()
        
        # Summary
        print("\n" + "=" * 80)
        print("üìä GENERATION 2 SUMMARY")
        print("=" * 80)
        
        successful_demos = []
        failed_demos = []
        
        for demo_name, results in all_results.items():
            if isinstance(results, dict) and "error" not in results:
                successful_demos.append(demo_name)
            else:
                failed_demos.append(demo_name)
        
        print(f"‚úÖ Successful demos: {len(successful_demos)}/{len(all_results)}")
        for demo in successful_demos:
            print(f"  - {demo}")
        
        if failed_demos:
            print(f"‚ùå Failed demos: {len(failed_demos)}")
            for demo in failed_demos:
                print(f"  - {demo}")
        
        # Save complete results
        output_file = Path("generation2_robust_demo_results.json")
        with open(output_file, 'w') as f:
            json.dump(all_results, f, indent=2, default=str)
        
        print(f"\nüìÑ Complete results saved to: {output_file}")
        
        print("\nüéâ Generation 2 robust implementation demonstrated!")
        print("Key features working:")
        print("  ‚Ä¢ Comprehensive health monitoring")
        print("  ‚Ä¢ Advanced error handling and recovery")
        print("  ‚Ä¢ Circuit breaker fault tolerance")
        print("  ‚Ä¢ Retry mechanisms with exponential backoff")
        print("  ‚Ä¢ Ablation study framework")
        print("  ‚Ä¢ Production-ready monitoring systems")
        
        logger.info("Generation 2 demo completed successfully")
        
    except Exception as e:
        logger.error(f"Generation 2 demo failed: {e}")
        print(f"\n‚ùå Demo failed with error: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()