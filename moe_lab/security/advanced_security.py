"""Advanced security system for MoE models with comprehensive protection.

This module provides enterprise-grade security features:
1. Input validation and sanitization
2. Model integrity verification
3. Secure checkpoint handling
4. Access control and authentication
5. Audit logging and monitoring
6. Encryption for sensitive data
7. Adversarial attack detection and mitigation
"""

import hashlib
import hmac
import secrets
import logging
import time
import json
import pickle
from typing import Any, Dict, List, Optional, Tuple, Union, Callable
from dataclasses import dataclass, field
from enum import Enum
import threading
from pathlib import Path
import re
import base64
from collections import defaultdict, deque
import functools


class SecurityLevel(Enum):
    """Security level classifications."""
    PUBLIC = "public"
    INTERNAL = "internal"
    CONFIDENTIAL = "confidential"
    RESTRICTED = "restricted"


class ThreatType(Enum):
    """Types of security threats."""
    ADVERSARIAL_INPUT = "adversarial_input"
    MODEL_POISONING = "model_poisoning"
    DATA_EXTRACTION = "data_extraction"
    UNAUTHORIZED_ACCESS = "unauthorized_access"
    INTEGRITY_VIOLATION = "integrity_violation"
    DENIAL_OF_SERVICE = "denial_of_service"


@dataclass
class SecurityEvent:
    """Security event record."""
    event_id: str
    timestamp: float
    event_type: ThreatType
    severity: str  # 'low', 'medium', 'high', 'critical'
    source_ip: Optional[str] = None
    user_id: Optional[str] = None
    details: Dict[str, Any] = field(default_factory=dict)
    action_taken: Optional[str] = None
    resolved: bool = False


@dataclass
class AccessPolicy:
    """Access control policy."""
    resource_pattern: str
    allowed_users: List[str] = field(default_factory=list)
    allowed_roles: List[str] = field(default_factory=list)
    required_permissions: List[str] = field(default_factory=list)
    security_level: SecurityLevel = SecurityLevel.INTERNAL
    rate_limit: Optional[int] = None  # requests per minute
    time_restrictions: Optional[Dict[str, Any]] = None


class InputValidator:
    """Comprehensive input validation and sanitization."""
    
    def __init__(self, strict_mode: bool = True):
        self.strict_mode = strict_mode
        self.validation_rules = {}
        self.sanitization_rules = {}
        
        # Setup default validation rules
        self._setup_default_rules()
        
    def _setup_default_rules(self):
        """Setup default validation and sanitization rules."""
        
        # Tensor validation rules
        self.validation_rules['tensor'] = [
            self._validate_tensor_shape,
            self._validate_tensor_dtype,
            self._validate_tensor_range,
            self._check_tensor_anomalies
        ]
        
        # String validation rules
        self.validation_rules['string'] = [
            self._validate_string_length,
            self._validate_string_content,
            self._check_injection_patterns
        ]
        
        # Numeric validation rules
        self.validation_rules['numeric'] = [
            self._validate_numeric_range,
            self._validate_numeric_type,
            self._check_numeric_anomalies
        ]
        
        # File validation rules
        self.validation_rules['file'] = [
            self._validate_file_extension,
            self._validate_file_size,
            self._scan_file_content
        ]
        
    def validate_input(
        self,
        data: Any,
        input_type: str,
        context: Optional[Dict[str, Any]] = None
    ) -> Tuple[bool, List[str], Any]:
        """
        Validate input data.
        
        Returns:
            Tuple of (is_valid, error_messages, sanitized_data)
        """
        errors = []
        sanitized_data = data
        
        if input_type not in self.validation_rules:
            if self.strict_mode:
                errors.append(f"Unknown input type: {input_type}")
                return False, errors, data
            else:
                return True, [], data
                
        # Apply validation rules
        for rule in self.validation_rules[input_type]:
            try:
                is_valid, rule_errors = rule(data, context or {})
                if not is_valid:
                    errors.extend(rule_errors)
                    
            except Exception as e:
                errors.append(f"Validation rule error: {str(e)}")
                
        # Apply sanitization if validation passes or in permissive mode
        if not errors or not self.strict_mode:
            try:
                sanitized_data = self._sanitize_input(data, input_type, context or {})
            except Exception as e:
                errors.append(f"Sanitization error: {str(e)}")
                
        is_valid = len(errors) == 0
        return is_valid, errors, sanitized_data
        
    def _sanitize_input(self, data: Any, input_type: str, context: Dict[str, Any]) -> Any:
        """Sanitize input data."""
        if input_type == 'string':
            # Remove potentially dangerous characters
            sanitized = re.sub(r'[<>&"\']', '', str(data))
            # Limit length
            max_length = context.get('max_length', 10000)
            sanitized = sanitized[:max_length]
            return sanitized
            
        elif input_type == 'tensor':
            try:
                import torch
                if isinstance(data, torch.Tensor):
                    # Clamp values to reasonable range
                    min_val = context.get('min_value', -1e6)
                    max_val = context.get('max_value', 1e6)
                    return torch.clamp(data, min_val, max_val)
            except ImportError:
                pass
                
        return data
        
    def _validate_tensor_shape(self, data: Any, context: Dict[str, Any]) -> Tuple[bool, List[str]]:\n        \"\"\"Validate tensor shape.\"\"\"\n        try:\n            import torch\n            if not isinstance(data, torch.Tensor):\n                return False, [\"Data is not a tensor\"]\n                \n            # Check dimension limits\n            max_dims = context.get('max_dimensions', 6)\n            if len(data.shape) > max_dims:\n                return False, [f\"Tensor has too many dimensions: {len(data.shape)} > {max_dims}\"]\n                \n            # Check size limits\n            max_elements = context.get('max_elements', 1e8)\n            if data.numel() > max_elements:\n                return False, [f\"Tensor too large: {data.numel()} > {max_elements}\"]\n                \n            return True, []\n            \n        except ImportError:\n            return True, []\n        except Exception as e:\n            return False, [f\"Tensor shape validation error: {str(e)}\"]\n            \n    def _validate_tensor_dtype(self, data: Any, context: Dict[str, Any]) -> Tuple[bool, List[str]]:\n        \"\"\"Validate tensor data type.\"\"\"\n        try:\n            import torch\n            if not isinstance(data, torch.Tensor):\n                return True, []  # Not a tensor, skip\n                \n            allowed_dtypes = context.get('allowed_dtypes', [\n                torch.float32, torch.float64, torch.int32, torch.int64\n            ])\n            \n            if data.dtype not in allowed_dtypes:\n                return False, [f\"Invalid tensor dtype: {data.dtype}\"]\n                \n            return True, []\n            \n        except ImportError:\n            return True, []\n        except Exception as e:\n            return False, [f\"Tensor dtype validation error: {str(e)}\"]\n            \n    def _validate_tensor_range(self, data: Any, context: Dict[str, Any]) -> Tuple[bool, List[str]]:\n        \"\"\"Validate tensor value range.\"\"\"\n        try:\n            import torch\n            if not isinstance(data, torch.Tensor):\n                return True, []\n                \n            # Check for NaN or Inf values\n            if torch.isnan(data).any():\n                return False, [\"Tensor contains NaN values\"]\n                \n            if torch.isinf(data).any():\n                return False, [\"Tensor contains infinite values\"]\n                \n            # Check value range\n            min_val = context.get('min_value', -1e6)\n            max_val = context.get('max_value', 1e6)\n            \n            if data.min() < min_val or data.max() > max_val:\n                return False, [f\"Tensor values out of range [{min_val}, {max_val}]\"]\n                \n            return True, []\n            \n        except ImportError:\n            return True, []\n        except Exception as e:\n            return False, [f\"Tensor range validation error: {str(e)}\"]\n            \n    def _check_tensor_anomalies(self, data: Any, context: Dict[str, Any]) -> Tuple[bool, List[str]]:\n        \"\"\"Check for tensor anomalies that might indicate adversarial inputs.\"\"\"\n        try:\n            import torch\n            if not isinstance(data, torch.Tensor):\n                return True, []\n                \n            warnings = []\n            \n            # Check for unusual patterns\n            if data.std() > 1000:\n                warnings.append(\"Tensor has very high standard deviation\")\n                \n            # Check for repetitive patterns\n            if data.numel() > 1000:\n                unique_ratio = data.unique().numel() / data.numel()\n                if unique_ratio < 0.01:\n                    warnings.append(\"Tensor has very low unique value ratio\")\n                    \n            # In strict mode, warnings are errors\n            if self.strict_mode and warnings:\n                return False, warnings\n                \n            return True, warnings\n            \n        except ImportError:\n            return True, []\n        except Exception as e:\n            return False, [f\"Tensor anomaly check error: {str(e)}\"]\n            \n    def _validate_string_length(self, data: Any, context: Dict[str, Any]) -> Tuple[bool, List[str]]:\n        \"\"\"Validate string length.\"\"\"\n        if not isinstance(data, str):\n            return True, []  # Not a string, skip\n            \n        max_length = context.get('max_length', 10000)\n        min_length = context.get('min_length', 0)\n        \n        if len(data) > max_length:\n            return False, [f\"String too long: {len(data)} > {max_length}\"]\n            \n        if len(data) < min_length:\n            return False, [f\"String too short: {len(data)} < {min_length}\"]\n            \n        return True, []\n        \n    def _validate_string_content(self, data: Any, context: Dict[str, Any]) -> Tuple[bool, List[str]]:\n        \"\"\"Validate string content.\"\"\"\n        if not isinstance(data, str):\n            return True, []\n            \n        # Check for null bytes\n        if '\\x00' in data:\n            return False, [\"String contains null bytes\"]\n            \n        # Check encoding\n        try:\n            data.encode('utf-8')\n        except UnicodeEncodeError:\n            return False, [\"String contains invalid UTF-8 characters\"]\n            \n        return True, []\n        \n    def _check_injection_patterns(self, data: Any, context: Dict[str, Any]) -> Tuple[bool, List[str]]:\n        \"\"\"Check for injection attack patterns.\"\"\"\n        if not isinstance(data, str):\n            return True, []\n            \n        # SQL injection patterns\n        sql_patterns = [\n            r'(\\b(SELECT|INSERT|UPDATE|DELETE|DROP|CREATE|ALTER)\\b)',\n            r'(UNION.*SELECT)',\n            r'(\\|\\|.*\\|\\|)',\n            r'(-{2,})',  # SQL comments\n        ]\n        \n        # Script injection patterns\n        script_patterns = [\n            r'<script[^>]*>.*?</script>',\n            r'javascript:',\n            r'on\\w+\\s*=',  # Event handlers\n        ]\n        \n        # Command injection patterns\n        command_patterns = [\n            r'[;&|`]',  # Command separators\n            r'\\$\\(',   # Command substitution\n            r'\\.\\./',  # Directory traversal\n        ]\n        \n        all_patterns = sql_patterns + script_patterns + command_patterns\n        \n        for pattern in all_patterns:\n            if re.search(pattern, data, re.IGNORECASE):\n                return False, [f\"Potential injection attack detected: pattern '{pattern}'\"]\n                \n        return True, []\n        \n    def _validate_numeric_range(self, data: Any, context: Dict[str, Any]) -> Tuple[bool, List[str]]:\n        \"\"\"Validate numeric range.\"\"\"\n        if not isinstance(data, (int, float)):\n            return True, []\n            \n        min_val = context.get('min_value', float('-inf'))\n        max_val = context.get('max_value', float('inf'))\n        \n        if data < min_val or data > max_val:\n            return False, [f\"Numeric value out of range: {data} not in [{min_val}, {max_val}]\"]\n            \n        return True, []\n        \n    def _validate_numeric_type(self, data: Any, context: Dict[str, Any]) -> Tuple[bool, List[str]]:\n        \"\"\"Validate numeric type.\"\"\"\n        if not isinstance(data, (int, float)):\n            return True, []\n            \n        # Check for NaN or Inf\n        if isinstance(data, float):\n            if data != data:  # NaN check\n                return False, [\"Numeric value is NaN\"]\n                \n            if abs(data) == float('inf'):\n                return False, [\"Numeric value is infinite\"]\n                \n        return True, []\n        \n    def _check_numeric_anomalies(self, data: Any, context: Dict[str, Any]) -> Tuple[bool, List[str]]:\n        \"\"\"Check for numeric anomalies.\"\"\"\n        if not isinstance(data, (int, float)):\n            return True, []\n            \n        warnings = []\n        \n        # Check for suspiciously precise values\n        if isinstance(data, float):\n            str_repr = str(data)\n            if len(str_repr.split('.')[-1]) > 10:\n                warnings.append(\"Suspiciously precise float value\")\n                \n        if self.strict_mode and warnings:\n            return False, warnings\n            \n        return True, warnings\n        \n    def _validate_file_extension(self, data: Any, context: Dict[str, Any]) -> Tuple[bool, List[str]]:\n        \"\"\"Validate file extension.\"\"\"\n        if not isinstance(data, (str, Path)):\n            return True, []\n            \n        filepath = Path(data)\n        allowed_extensions = context.get('allowed_extensions', ['.pt', '.pth', '.pkl', '.json'])\n        \n        if filepath.suffix.lower() not in allowed_extensions:\n            return False, [f\"File extension not allowed: {filepath.suffix}\"]\n            \n        return True, []\n        \n    def _validate_file_size(self, data: Any, context: Dict[str, Any]) -> Tuple[bool, List[str]]:\n        \"\"\"Validate file size.\"\"\"\n        if not isinstance(data, (str, Path)):\n            return True, []\n            \n        filepath = Path(data)\n        if not filepath.exists():\n            return False, [\"File does not exist\"]\n            \n        max_size = context.get('max_size_mb', 1000) * 1024 * 1024  # Convert to bytes\n        actual_size = filepath.stat().st_size\n        \n        if actual_size > max_size:\n            return False, [f\"File too large: {actual_size} > {max_size} bytes\"]\n            \n        return True, []\n        \n    def _scan_file_content(self, data: Any, context: Dict[str, Any]) -> Tuple[bool, List[str]]:\n        \"\"\"Scan file content for security threats.\"\"\"\n        if not isinstance(data, (str, Path)):\n            return True, []\n            \n        filepath = Path(data)\n        if not filepath.exists():\n            return True, []  # File existence already checked\n            \n        try:\n            # Check file headers/magic numbers\n            with open(filepath, 'rb') as f:\n                header = f.read(16)\n                \n            # Check for executable file signatures\n            executable_signatures = [\n                b'\\x4d\\x5a',  # PE executable\n                b'\\x7f\\x45\\x4c\\x46',  # ELF executable\n                b'\\xca\\xfe\\xba\\xbe',  # Mach-O executable\n            ]\n            \n            for sig in executable_signatures:\n                if header.startswith(sig):\n                    return False, [\"File appears to be an executable\"]\n                    \n            return True, []\n            \n        except Exception as e:\n            return False, [f\"File content scan error: {str(e)}\"]\n\n\nclass ModelIntegrityChecker:\n    \"\"\"Model integrity verification system.\"\"\"\n    \n    def __init__(self):\n        self.known_hashes = {}\n        self.signature_keys = {}\n        \n    def compute_model_hash(self, model_data: bytes, algorithm: str = 'sha256') -> str:\n        \"\"\"Compute hash of model data.\"\"\"\n        hash_func = getattr(hashlib, algorithm)()\n        hash_func.update(model_data)\n        return hash_func.hexdigest()\n        \n    def verify_model_integrity(\n        self,\n        model_data: bytes,\n        expected_hash: str,\n        algorithm: str = 'sha256'\n    ) -> bool:\n        \"\"\"Verify model integrity against expected hash.\"\"\"\n        actual_hash = self.compute_model_hash(model_data, algorithm)\n        return hmac.compare_digest(actual_hash, expected_hash)\n        \n    def sign_model(self, model_data: bytes, private_key: str) -> str:\n        \"\"\"Create digital signature for model.\"\"\"\n        # Simplified signature - in production, use proper cryptographic library\n        signature_data = f\"{private_key}:{hashlib.sha256(model_data).hexdigest()}\"\n        return base64.b64encode(signature_data.encode()).decode()\n        \n    def verify_signature(\n        self,\n        model_data: bytes,\n        signature: str,\n        public_key: str\n    ) -> bool:\n        \"\"\"Verify model signature.\"\"\"\n        try:\n            decoded_sig = base64.b64decode(signature.encode()).decode()\n            expected_key, expected_hash = decoded_sig.split(':', 1)\n            \n            # Verify key matches (simplified)\n            if expected_key != public_key:\n                return False\n                \n            # Verify hash\n            actual_hash = hashlib.sha256(model_data).hexdigest()\n            return hmac.compare_digest(actual_hash, expected_hash)\n            \n        except Exception:\n            return False\n            \n    def register_trusted_model(self, model_id: str, model_hash: str, signature: Optional[str] = None):\n        \"\"\"Register a trusted model with its hash and signature.\"\"\"\n        self.known_hashes[model_id] = {\n            'hash': model_hash,\n            'signature': signature,\n            'registered_at': time.time()\n        }\n        \n    def is_trusted_model(self, model_id: str, model_data: bytes) -> bool:\n        \"\"\"Check if model is in trusted registry.\"\"\"\n        if model_id not in self.known_hashes:\n            return False\n            \n        trusted_info = self.known_hashes[model_id]\n        actual_hash = self.compute_model_hash(model_data)\n        \n        return hmac.compare_digest(actual_hash, trusted_info['hash'])\n\n\nclass AccessController:\n    \"\"\"Access control and authentication system.\"\"\"\n    \n    def __init__(self):\n        self.users = {}  # user_id -> user_info\n        self.roles = {}  # role_name -> permissions\n        self.policies = []  # List of access policies\n        self.active_sessions = {}  # session_id -> session_info\n        self.rate_limits = defaultdict(lambda: deque(maxlen=1000))  # user_id -> request_times\n        self.lock = threading.RLock()\n        \n    def create_user(\n        self,\n        user_id: str,\n        password_hash: str,\n        roles: List[str] = None,\n        permissions: List[str] = None\n    ):\n        \"\"\"Create a new user.\"\"\"\n        with self.lock:\n            self.users[user_id] = {\n                'password_hash': password_hash,\n                'roles': roles or [],\n                'permissions': permissions or [],\n                'created_at': time.time(),\n                'last_login': None,\n                'login_attempts': 0,\n                'locked': False\n            }\n            \n    def authenticate_user(self, user_id: str, password: str) -> Optional[str]:\n        \"\"\"Authenticate user and return session token.\"\"\"\n        with self.lock:\n            if user_id not in self.users:\n                return None\n                \n            user = self.users[user_id]\n            \n            # Check if account is locked\n            if user.get('locked', False):\n                return None\n                \n            # Verify password (simplified - use proper hashing in production)\n            if not self._verify_password(password, user['password_hash']):\n                user['login_attempts'] += 1\n                \n                # Lock account after too many failed attempts\n                if user['login_attempts'] >= 5:\n                    user['locked'] = True\n                    \n                return None\n                \n            # Successful authentication\n            user['last_login'] = time.time()\n            user['login_attempts'] = 0\n            \n            # Create session\n            session_id = secrets.token_urlsafe(32)\n            self.active_sessions[session_id] = {\n                'user_id': user_id,\n                'created_at': time.time(),\n                'last_activity': time.time(),\n                'ip_address': None  # Would be set by calling code\n            }\n            \n            return session_id\n            \n    def _verify_password(self, password: str, password_hash: str) -> bool:\n        \"\"\"Verify password against hash (simplified).\"\"\"\n        # In production, use proper password hashing like bcrypt\n        return hashlib.sha256(password.encode()).hexdigest() == password_hash\n        \n    def validate_session(self, session_id: str) -> Optional[str]:\n        \"\"\"Validate session and return user_id if valid.\"\"\"\n        with self.lock:\n            if session_id not in self.active_sessions:\n                return None\n                \n            session = self.active_sessions[session_id]\n            \n            # Check session timeout (1 hour)\n            if time.time() - session['last_activity'] > 3600:\n                del self.active_sessions[session_id]\n                return None\n                \n            # Update last activity\n            session['last_activity'] = time.time()\n            return session['user_id']\n            \n    def check_permission(\n        self,\n        user_id: str,\n        resource: str,\n        action: str\n    ) -> bool:\n        \"\"\"Check if user has permission for action on resource.\"\"\"\n        with self.lock:\n            if user_id not in self.users:\n                return False\n                \n            user = self.users[user_id]\n            \n            # Check direct permissions\n            required_permission = f\"{resource}:{action}\"\n            if required_permission in user['permissions']:\n                return True\n                \n            # Check role-based permissions\n            for role in user['roles']:\n                if role in self.roles:\n                    if required_permission in self.roles[role]:\n                        return True\n                        \n            # Check policies\n            for policy in self.policies:\n                if self._matches_policy(user_id, resource, action, policy):\n                    return True\n                    \n            return False\n            \n    def _matches_policy(\n        self,\n        user_id: str,\n        resource: str,\n        action: str,\n        policy: AccessPolicy\n    ) -> bool:\n        \"\"\"Check if user action matches access policy.\"\"\"\n        # Check resource pattern\n        if not re.match(policy.resource_pattern, resource):\n            return False\n            \n        user = self.users[user_id]\n        \n        # Check user whitelist\n        if policy.allowed_users and user_id not in policy.allowed_users:\n            return False\n            \n        # Check role requirements\n        if policy.allowed_roles:\n            if not any(role in policy.allowed_roles for role in user['roles']):\n                return False\n                \n        # Check permission requirements\n        if policy.required_permissions:\n            required_perm = f\"{resource}:{action}\"\n            if required_perm not in policy.required_permissions:\n                return False\n                \n        return True\n        \n    def check_rate_limit(self, user_id: str, limit_per_minute: int = 60) -> bool:\n        \"\"\"Check if user is within rate limit.\"\"\"\n        current_time = time.time()\n        \n        with self.lock:\n            user_requests = self.rate_limits[user_id]\n            \n            # Remove old requests (older than 1 minute)\n            while user_requests and current_time - user_requests[0] > 60:\n                user_requests.popleft()\n                \n            # Check current rate\n            if len(user_requests) >= limit_per_minute:\n                return False\n                \n            # Record this request\n            user_requests.append(current_time)\n            return True\n\n\nclass SecurityEventMonitor:\n    \"\"\"Security event monitoring and incident response.\"\"\"\n    \n    def __init__(self, max_events: int = 10000):\n        self.events = deque(maxlen=max_events)\n        self.threat_patterns = {}\n        self.response_handlers = {}\n        self.lock = threading.RLock()\n        \n        # Setup default threat detection patterns\n        self._setup_threat_patterns()\n        \n    def _setup_threat_patterns(self):\n        \"\"\"Setup default threat detection patterns.\"\"\"\n        \n        # Brute force login attempts\n        self.threat_patterns['brute_force'] = {\n            'window_seconds': 300,  # 5 minutes\n            'threshold_count': 10,\n            'event_filter': lambda e: 'login_failed' in e.details\n        }\n        \n        # Unusual access patterns\n        self.threat_patterns['unusual_access'] = {\n            'window_seconds': 3600,  # 1 hour\n            'threshold_count': 100,\n            'event_filter': lambda e: e.event_type == ThreatType.UNAUTHORIZED_ACCESS\n        }\n        \n    def log_security_event(\n        self,\n        event_type: ThreatType,\n        severity: str,\n        details: Dict[str, Any],\n        source_ip: Optional[str] = None,\n        user_id: Optional[str] = None\n    ) -> str:\n        \"\"\"Log a security event and return event ID.\"\"\"\n        \n        event_id = secrets.token_urlsafe(16)\n        \n        event = SecurityEvent(\n            event_id=event_id,\n            timestamp=time.time(),\n            event_type=event_type,\n            severity=severity,\n            source_ip=source_ip,\n            user_id=user_id,\n            details=details\n        )\n        \n        with self.lock:\n            self.events.append(event)\n            \n        # Check for threat patterns\n        self._analyze_threat_patterns(event)\n        \n        # Log to system logger\n        log_level = {\n            'low': logging.INFO,\n            'medium': logging.WARNING,\n            'high': logging.ERROR,\n            'critical': logging.CRITICAL\n        }.get(severity, logging.WARNING)\n        \n        logging.log(\n            log_level,\n            f\"Security Event [{event_id}]: {event_type.value} - {details}\"\n        )\n        \n        return event_id\n        \n    def _analyze_threat_patterns(self, new_event: SecurityEvent):\n        \"\"\"Analyze events for threat patterns.\"\"\"\n        current_time = time.time()\n        \n        for pattern_name, pattern_config in self.threat_patterns.items():\n            window_seconds = pattern_config['window_seconds']\n            threshold_count = pattern_config['threshold_count']\n            event_filter = pattern_config['event_filter']\n            \n            # Count matching events in time window\n            matching_events = 0\n            \n            for event in reversed(self.events):\n                if current_time - event.timestamp > window_seconds:\n                    break\n                    \n                if event_filter(event):\n                    matching_events += 1\n                    \n            # Check if threshold exceeded\n            if matching_events >= threshold_count:\n                self._handle_threat_detection(\n                    pattern_name,\n                    matching_events,\n                    new_event\n                )\n                \n    def _handle_threat_detection(\n        self,\n        pattern_name: str,\n        event_count: int,\n        trigger_event: SecurityEvent\n    ):\n        \"\"\"Handle detected threat pattern.\"\"\"\n        \n        threat_event_id = self.log_security_event(\n            ThreatType.DENIAL_OF_SERVICE,\n            'high',\n            {\n                'threat_pattern': pattern_name,\n                'event_count': event_count,\n                'trigger_event_id': trigger_event.event_id\n            },\n            source_ip=trigger_event.source_ip,\n            user_id=trigger_event.user_id\n        )\n        \n        # Execute response handlers\n        if pattern_name in self.response_handlers:\n            try:\n                self.response_handlers[pattern_name](trigger_event, event_count)\n            except Exception as e:\n                logging.error(f\"Threat response handler error: {e}\")\n                \n    def register_response_handler(\n        self,\n        pattern_name: str,\n        handler: Callable[[SecurityEvent, int], None]\n    ):\n        \"\"\"Register threat response handler.\"\"\"\n        self.response_handlers[pattern_name] = handler\n        \n    def get_security_summary(self, hours: int = 24) -> Dict[str, Any]:\n        \"\"\"Get security summary for the last N hours.\"\"\"\n        cutoff_time = time.time() - (hours * 3600)\n        \n        recent_events = [\n            event for event in self.events\n            if event.timestamp >= cutoff_time\n        ]\n        \n        summary = {\n            'total_events': len(recent_events),\n            'by_type': defaultdict(int),\n            'by_severity': defaultdict(int),\n            'unique_sources': set(),\n            'unique_users': set()\n        }\n        \n        for event in recent_events:\n            summary['by_type'][event.event_type.value] += 1\n            summary['by_severity'][event.severity] += 1\n            \n            if event.source_ip:\n                summary['unique_sources'].add(event.source_ip)\n            if event.user_id:\n                summary['unique_users'].add(event.user_id)\n                \n        # Convert sets to counts\n        summary['unique_sources'] = len(summary['unique_sources'])\n        summary['unique_users'] = len(summary['unique_users'])\n        summary['by_type'] = dict(summary['by_type'])\n        summary['by_severity'] = dict(summary['by_severity'])\n        \n        return summary\n\n\nclass AdvancedSecuritySystem:\n    \"\"\"Comprehensive security system orchestrator.\"\"\"\n    \n    def __init__(self, config: Optional[Dict[str, Any]] = None):\n        self.config = config or {}\n        \n        # Initialize security components\n        self.input_validator = InputValidator(\n            strict_mode=self.config.get('strict_validation', True)\n        )\n        \n        self.integrity_checker = ModelIntegrityChecker()\n        self.access_controller = AccessController()\n        self.event_monitor = SecurityEventMonitor()\n        \n        # Setup default security policies\n        self._setup_default_policies()\n        \n        # Setup default threat response\n        self._setup_threat_responses()\n        \n    def _setup_default_policies(self):\n        \"\"\"Setup default security policies.\"\"\"\n        \n        # Admin access policy\n        admin_policy = AccessPolicy(\n            resource_pattern=r'.*',\n            allowed_roles=['admin'],\n            security_level=SecurityLevel.RESTRICTED\n        )\n        self.access_controller.policies.append(admin_policy)\n        \n        # Model access policy\n        model_policy = AccessPolicy(\n            resource_pattern=r'model/.*',\n            allowed_roles=['researcher', 'admin'],\n            required_permissions=['model:read'],\n            security_level=SecurityLevel.CONFIDENTIAL,\n            rate_limit=100  # 100 requests per minute\n        )\n        self.access_controller.policies.append(model_policy)\n        \n    def _setup_threat_responses(self):\n        \"\"\"Setup default threat response handlers.\"\"\"\n        \n        def brute_force_response(event: SecurityEvent, count: int):\n            \"\"\"Response to brute force attacks.\"\"\"\n            if event.source_ip:\n                logging.critical(f\"Brute force attack detected from {event.source_ip} ({count} attempts)\")\n                # In production: add IP to blocklist, notify administrators\n                \n        def unusual_access_response(event: SecurityEvent, count: int):\n            \"\"\"Response to unusual access patterns.\"\"\"\n            logging.warning(f\"Unusual access pattern detected: {count} events\")\n            # In production: increase monitoring, require additional authentication\n            \n        self.event_monitor.register_response_handler('brute_force', brute_force_response)\n        self.event_monitor.register_response_handler('unusual_access', unusual_access_response)\n        \n    def secure_validate_input(\n        self,\n        data: Any,\n        input_type: str,\n        context: Optional[Dict[str, Any]] = None,\n        user_id: Optional[str] = None,\n        source_ip: Optional[str] = None\n    ) -> Tuple[bool, List[str], Any]:\n        \"\"\"Securely validate input with security event logging.\"\"\"\n        \n        # Perform validation\n        is_valid, errors, sanitized_data = self.input_validator.validate_input(\n            data, input_type, context\n        )\n        \n        # Log security events for validation failures\n        if not is_valid:\n            self.event_monitor.log_security_event(\n                ThreatType.ADVERSARIAL_INPUT,\n                'medium',\n                {\n                    'input_type': input_type,\n                    'validation_errors': errors,\n                    'data_summary': str(data)[:100] if isinstance(data, str) else type(data).__name__\n                },\n                source_ip=source_ip,\n                user_id=user_id\n            )\n            \n        return is_valid, errors, sanitized_data\n        \n    def secure_model_access(\n        self,\n        user_id: str,\n        model_id: str,\n        action: str = 'read',\n        source_ip: Optional[str] = None\n    ) -> bool:\n        \"\"\"Securely control model access.\"\"\"\n        \n        # Check rate limiting\n        if not self.access_controller.check_rate_limit(user_id):\n            self.event_monitor.log_security_event(\n                ThreatType.DENIAL_OF_SERVICE,\n                'medium',\n                {'reason': 'rate_limit_exceeded', 'model_id': model_id},\n                source_ip=source_ip,\n                user_id=user_id\n            )\n            return False\n            \n        # Check permissions\n        has_permission = self.access_controller.check_permission(\n            user_id, f'model/{model_id}', action\n        )\n        \n        if not has_permission:\n            self.event_monitor.log_security_event(\n                ThreatType.UNAUTHORIZED_ACCESS,\n                'high',\n                {'model_id': model_id, 'action': action},\n                source_ip=source_ip,\n                user_id=user_id\n            )\n            return False\n            \n        # Log successful access\n        self.event_monitor.log_security_event(\n            ThreatType.UNAUTHORIZED_ACCESS,  # Using as general access log\n            'low',\n            {'model_id': model_id, 'action': action, 'status': 'granted'},\n            source_ip=source_ip,\n            user_id=user_id\n        )\n        \n        return True\n        \n    def get_security_dashboard(self) -> Dict[str, Any]:\n        \"\"\"Get comprehensive security dashboard.\"\"\"\n        return {\n            'timestamp': time.time(),\n            'security_summary': self.event_monitor.get_security_summary(),\n            'active_sessions': len(self.access_controller.active_sessions),\n            'registered_users': len(self.access_controller.users),\n            'trusted_models': len(self.integrity_checker.known_hashes),\n            'threat_patterns': list(self.event_monitor.threat_patterns.keys()),\n            'security_level': 'HIGH'  # Could be computed based on recent events\n        }\n        \n    def export_security_report(self, filepath: str):\n        \"\"\"Export comprehensive security report.\"\"\"\n        report = {\n            'report_timestamp': time.time(),\n            'security_dashboard': self.get_security_dashboard(),\n            'configuration': {\n                'strict_validation': self.input_validator.strict_mode,\n                'session_timeout': 3600,\n                'rate_limit_default': 60\n            }\n        }\n        \n        Path(filepath).parent.mkdir(parents=True, exist_ok=True)\n        \n        with open(filepath, 'w') as f:\n            json.dump(report, f, indent=2, default=str)\n            \n        logging.info(f\"Security report exported to {filepath}\")\n\n\n# Security decorators\n\ndef secure_endpoint(\n    required_permissions: List[str] = None,\n    rate_limit: int = 60,\n    input_validation: Dict[str, str] = None,\n    security_system: Optional[AdvancedSecuritySystem] = None\n):\n    \"\"\"Decorator for securing API endpoints.\"\"\"\n    \n    def decorator(func: Callable) -> Callable:\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            # Extract security context (would be provided by web framework)\n            user_id = kwargs.pop('_user_id', None)\n            source_ip = kwargs.pop('_source_ip', None)\n            session_id = kwargs.pop('_session_id', None)\n            \n            system = security_system or _get_global_security_system()\n            \n            # Validate session\n            if session_id:\n                validated_user = system.access_controller.validate_session(session_id)\n                if not validated_user or validated_user != user_id:\n                    raise PermissionError(\"Invalid session\")\n                    \n            # Check rate limiting\n            if user_id and not system.access_controller.check_rate_limit(user_id, rate_limit):\n                raise PermissionError(\"Rate limit exceeded\")\n                \n            # Validate inputs\n            if input_validation:\n                for param, input_type in input_validation.items():\n                    if param in kwargs:\n                        is_valid, errors, sanitized = system.secure_validate_input(\n                            kwargs[param],\n                            input_type,\n                            user_id=user_id,\n                            source_ip=source_ip\n                        )\n                        \n                        if not is_valid:\n                            raise ValueError(f\"Input validation failed for {param}: {errors}\")\n                            \n                        kwargs[param] = sanitized\n                        \n            # Check permissions\n            if required_permissions and user_id:\n                resource = f\"endpoint/{func.__name__}\"\n                for permission in required_permissions:\n                    if not system.access_controller.check_permission(\n                        user_id, resource, permission\n                    ):\n                        raise PermissionError(f\"Missing permission: {permission}\")\n                        \n            return func(*args, **kwargs)\n            \n        return wrapper\n    return decorator\n\n\n# Global security system\n_global_security_system = None\n\n\ndef _get_global_security_system() -> AdvancedSecuritySystem:\n    \"\"\"Get or create global security system.\"\"\"\n    global _global_security_system\n    if _global_security_system is None:\n        _global_security_system = AdvancedSecuritySystem()\n    return _global_security_system\n\n\ndef set_global_security_system(system: AdvancedSecuritySystem):\n    \"\"\"Set global security system.\"\"\"\n    global _global_security_system\n    _global_security_system = system\n\n\n# Export security components\n__all__ = [\n    'SecurityLevel',\n    'ThreatType',\n    'SecurityEvent',\n    'AccessPolicy',\n    'InputValidator',\n    'ModelIntegrityChecker',\n    'AccessController',\n    'SecurityEventMonitor',\n    'AdvancedSecuritySystem',\n    'secure_endpoint',\n    'set_global_security_system'\n]